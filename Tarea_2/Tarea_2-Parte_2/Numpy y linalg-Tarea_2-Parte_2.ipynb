{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Galileo**\n",
    "\n",
    "**Ciencia de Datos en Python**\n",
    "\n",
    "**Nombre: Rodrigo Chang**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "En ML usamos la entropía cruzada como una forma de medir que tan bueno es un modelo de variables discretas a través de comparar la distribución de probabilidad que el modelo produce o predice, vs la distribución de probabilidad real dada por los datos de entrenamiento.\n",
    "\n",
    "Podemos ver el siguiente ejemplo que define la forma en que se calcula la entropía cruzada y nos muestra un caso específico:\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/publishintroductiontodeeplearninginpythonandmatlab1-160502102437/95/introduction-to-deep-learning-in-python-and-matlab-54-638.jpg?cb=1462185644\">\n",
    "\n",
    "En este caso interpretamos así: El problema consiste en un modelo o algoritmo de ML que debe producir un vector de 3 elementos indicando la probabilidad de que ciertos datos X pertenezcan a una de 3 categorías.\n",
    "\n",
    "* El modelo de ML produce un vector que indica que estima un 70% de probabilidad de que se trate de la categoría 0, 20% de probabilidad de que se trate de la categoría 1 y 10% de que se trate de la categoría 2.\n",
    "* Los datos reales nos dicen que se trataba de un caso donde con total certeza se sabe que se trata de la categoría 0\n",
    "* La entropía cruzada(a calcular en el ejercicio) nos indica que tan buena es la estimación del modelo, una EC de 0 es un modelo perfecto(en este caso un modelo que predice 100% de prob para la clase 0)\n",
    "\n",
    "**Nota** \n",
    "* Aun que para calcular la entropía usamos logaritmos en base 2, en ML para calcular la entropía cruzada se usa logaritmo natural ya que con este se cumple el proposito **estimar que tanto se alejan las predicciones del modelo de ML de los datos reales** y es comun]mente mas rápido de calcular en la computadora.\n",
    "* Ya que estamos trabajando con vectores que representan distribuciones de probabilidad , podemos toparnos con lo que se conoce como : **sparse vectors**(vectores donde la mayoría de elementos son 0), esto puede producir problemas ya que le logaritmo de 0 no esta definido, tu solución debe tomar en cuenta esto y evitar que devuelva \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(Y,Y_hat):\n",
    "    ## tu codigo aqui (~ 1 lineas de codigo)\n",
    "    def crossEntropyLog(x):\n",
    "        y = x.copy()\n",
    "        y[y <= 0] = 0\n",
    "        y[y > 0] = np.log(y[y > 0])\n",
    "        return y\n",
    "    \n",
    "    return -np.inner(Y, crossEntropyLog(Y_hat))\n",
    "    ##\n",
    "\n",
    "y  = np.array([1.0,0,0])\n",
    "y_hat = np.array([0.7, 0.2, 0.1])\n",
    "\n",
    "cross_entropy(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Magnitud de un Vector(norma o módulo)\n",
    " \n",
    "\n",
    "Matemáticamente la magnitud de un vector(también conocida como norma vectorial)  nos indica  el tamaño de este , y nos sirve para tener una noción de la distancia desde un punto de referencia(origen) hasta el punto representado por el vector.\n",
    "\n",
    "\n",
    "## Ejercicio 2\n",
    "Crear una función que reciba como parámetro un vector x y calcule su magnitud o norma(euclidiana o L2) ,luego usarla para evaluar 2 vectores que representan los errores generados por 2 modelos de machine learning y concluir cual de los 2 modelos es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "def magnitud(x):\n",
    "    ## tu codigo aqui (~ 1 linea de codigo)\n",
    "    return np.sqrt(np.inner(x, x))\n",
    "    ##\n",
    "    \n",
    "\n",
    "errores_modelo1 = np.array([1,2,1,2])\n",
    "errores_modelo2 = np.array([0,1,1,2])\n",
    "\n",
    "print(magnitud(errores_modelo1))\n",
    "print(magnitud(errores_modelo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** De los resultados parece que el modelo 2 es mejor, pues la magnitud de los errores del modelo 2 es menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Usando la función del ejercicio anterior, crea otra función normalizar(x) que reciba de parámetro un vector x aplique normalización sobre este, el resultado debe ser un nuevo vector del tamaño de x cuya magnitud es igual a 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0.         0.40824829 0.40824829 0.81649658]\n"
     ]
    }
   ],
   "source": [
    "def normalizar(x):\n",
    "    ## tu codigo aqui (~ 3 linea de codigo)\n",
    "    return x / magnitud(x)\n",
    "    ##\n",
    "\n",
    "print(magnitud(normalizar(errores_modelo1)))\n",
    "print(normalizar(errores_modelo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producto Punto(escalar,interno,interior) y Ortogonalidad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "### Aplicado en DS\n",
    "\n",
    "Se tiene una red neuronal sencilla(y simplificada) como la de la siguiente imagen:\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-convolutional-neural/9781788392303/assets/246151fb-7893-448d-b9bb-7a87b387a24b.png\">\n",
    "\n",
    "Donde:\n",
    "* INPUT LAYER: un vector X de tamaño = 2 que representa los datos de entrada\n",
    "* HIDDEN_LAYER :capa oculta con 2 neuronas definidas por los vectores:\n",
    "    * HL1 = [0.25,0.37]\n",
    "    * HL2 = [-8,14]\n",
    "* OUTPUT_LAYER = capa de salida definida por el vector [4,9]\n",
    "\n",
    "Crear una funcion `neural_network(X)` para calcular:\n",
    "* Calcule la salida de cada neurona en la capa intermedia aplicada a la capa de entrada.\n",
    "* Use el resultado del paso anterior como entrada para la neurona en la capa de salida\n",
    "\n",
    "Asumiendo que cada neurona identifica la similitud entre su entrada y la caracteística que representa concluir:\n",
    "* Para cada vector de entrada Xi , cual neurona intermedia busca la característica que mas se parece a X.\n",
    "* Cual vector de entrada Xi produce una activación alta(salida alta) en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la red neuronal sobre los siguientes datos X\n",
    "\n",
    "X1 = np.array([0.50,0.72])\n",
    "X2 = np.array([-4,7])\n",
    "X3 = np.zeros_like(X2)\n",
    "X4 = np.ones_like(X1)\n",
    "X5 = np.random.randn(X1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación de X= [0.5  0.72] es f(X)= 56.2856\n",
      "Evaluación de X= [-4  7] es f(X)= 1176.36\n",
      "Evaluación de X= [0 0] es f(X)= 0.0\n",
      "Evaluación de X= [1. 1.] es f(X)= 56.48\n",
      "Evaluación de X= [ 0.17775621 -0.26171092] es f(X)= -45.983598582358546\n"
     ]
    }
   ],
   "source": [
    "## tu codigo aqui:\n",
    "\n",
    "HL1 = np.array([0.25, 0.37])\n",
    "HL2 = np.array([-8, 14])\n",
    "OL = np.array([4, 9])\n",
    "\n",
    "def neural_network(X, w1 = HL1, w2 = HL2, wo = OL):\n",
    "    N1 = np.inner(X, w1)\n",
    "    N2 = np.inner(X, w2)\n",
    "    Y = np.inner(np.array([N1, N2]), wo)\n",
    "    return Y\n",
    "\n",
    "X = [X1, X2, X3, X4, X5]\n",
    "for elem in X: \n",
    "    print(\"Evaluación de X=\", elem, \"es f(X)=\", neural_network(elem))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La neurona intermedia que busca la característica que más se parece a X es la neurona 2 (la de abajo), cuyos pesos sinápticos son (-8, 14), pues esta neurona produce los valores de activación más altos. \n",
    "\n",
    "* La entrada que produce una activación más alta es $X_2 = (-4, 7)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 (aplicado en DS)\n",
    "La correlación cruzada es una medida de similitud entre 2 funciones como resultado de \"desplazar\" una sobre la otra, comunmente es usada para encontrar características relevantes en una función desconocida o no controlada.\n",
    "\n",
    "En procesamiento de señales por ejemplo es usada para buscar y/o filtrar en una señal que varia en el tiempo cierta caracaterística de interés. Aveces es llamada también \"sliding dot product\" consiste en aplicar en cada punto de una función F el producto punto con cierta función G(comunmente mas corta) y luego \"deslizar\" G a un nuevo punto de la función, el resultado es una nueva función H que se interpreta como :**cuanto se parece** en cada punto la función F a la característica G. \n",
    "\n",
    "<img src=\"https://i.makeagif.com/media/11-25-2015/LZ9Ufj.gif\"  height=\"250\" width=\"300\">\n",
    "\n",
    "En este ejercicio usamos correlación cruzada para calcular las medias moviles promediando 3 puntos que ya vimos en otro ejemplo:\n",
    "\n",
    "El primer paso es definir la función G que define el \"filtro\" a aplicar, para este caso consiste simplemente en un vector con 3 elementos donde cada elemento corresponde a 1/3, luego debemos aplicar el producto punto sobre cada punto de la función o datos originales(en este ejemplo llamados x) a traves aplicar el producto punto en cada elemento \"corriendolo\" de uno en uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruido = 0.1*np.random.randn(15) #el ruido comunmente se debe a aleatoriedad o captura no exacta de info.\n",
    "x = np.linspace(0,2*np.pi,15) + ruido\n",
    "x = np.sin(x)\n",
    "\n",
    "filtro = np.array([1/3,1/3,1/3])\n",
    "\n",
    "## tu codigo aqui (~ 3 linea de codigo)\n",
    "xs = x.copy()\n",
    "for i in range(1,len(x)-1):\n",
    "    xs[i] = np.inner(xs[i-1:i+2], filtro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operadores logicos en vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "Dado el vector x, usar operadores lógicos sobre vectores y acceso a  elementos usando vectores booleanos , escribir un programa que calcule eun nuevo vector z conteniendo el valor absoluto de el vector x.\n",
    "\n",
    "**Nota** No se puede usar np.abs() ni ciclos\n",
    "\n",
    "**Tip** usar un vector booleano para saber que elementos son negativos y deben ser multiplicados por -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,9)\n",
    "\n",
    "\n",
    "## tu codigo aqui (~ 4 linea de codigo)\n",
    "def otroAbs(x):\n",
    "    z = x.copy()\n",
    "    z[z<0] = -z[z<0]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Ejercicio 7\n",
    "Implementar la función:\n",
    "$$h(x) = \\begin{cases}0 & x< 0\\\\1 & 0<=x\n",
    "\n",
    "$$h(x) = \\begin{cases}0 & x< 0\\\\1 & 0<=x <=1\\\\0 & x> 1\\end{cases}$$\n",
    "\n",
    "Esta debe funcionar para vectores de cualquier tamaño x:\n",
    "\n",
    "```\n",
    "def h(x):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "```\n",
    "**nota** debe ser implementada sin ciclos o ifs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "def h(x):\n",
    "    ## tu codigo aqui (~ 3 linea de codigo)\n",
    "    cond = [x < 0, (x >= 0)*(x <= 1), x > 1]\n",
    "    res = [0, 1, 0]\n",
    "    h = np.select(cond, res)\n",
    "    ##\n",
    "    return h\n",
    "\n",
    "x = np.array([0.1,-2,0.5,5])\n",
    "print(h(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para casos donde se requiere comportamiento parecido a este pero con mas condiciones, NumPy provee la función **np.select** , la descripción de esta función casi siempre es mas complicada de lo que debería y dificulta entenderla, vamos a buscar entenderla bajo un ejemplo.\n",
    "\n",
    "Básicamente select se basa en :\n",
    "* una lista de condiciones A\n",
    "* una lista de valores a tomar según estas condiciones B\n",
    "* un valor de  resultado default cuando ninguna de las condiciones en la  lista se cumple.\n",
    "Estas 2 listas deben ser del mismo tamañaño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select y performance\n",
    "\n",
    "Usando select implementar una función k(x) con la siguiente definición:\n",
    "$$k(x) = \\begin{cases}-x & x< 0\\\\x^{3}  &0<=x<1\\\\x^{2}  &1<=x<2\\\\4  &otherwise\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aun que select es muy conveniente y útil , no es la opción mas eficiente esto debido a que evalua todas las condiciones y todos los resultados, en programación en general buscamos escribir los programas de la manera mas eficiente posible y evitar calculos innecesarios, esto se vuelve vital en ciencia de datos cuando procesamos grandes volúmenes de información, por eso NumPy nos provee la alternativa a select llamada **piecewise** que funciona de manera similar .\n",
    "\n",
    "Este funciona similar a select pero en vez de calcular todos los posibles resultados, calcula solo aquellos para los que la condición es True e ignora los False,sintácticamente piecewise requiere que los \"resultados\" sesan calcuados usando una lista de funciones por lo cual todos los resultados deben estar contenidos en una función  y el objeto función ser enviado a piecewise (si la función solo se utiliza una vez para este propósito, se puede usar funciones anónimas o lambda).\n",
    "\n",
    "## Ejercicio 8\n",
    "\n",
    "Investigar piecewise:\n",
    "*  Usarlo para implementar la función anterior de manera eficiente\n",
    "*  Usar piscewise para implementar la función:\n",
    "\n",
    "$$m(x) = \\begin{cases}e^{2x} & x< 0\\\\1  &0<=x<=1\\\\e^{1-x}  &x<=1\\\\\\end{cases}$$\n",
    "\n",
    "Nuevamente, sin utilizar ciclos ni ifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2. , -1.5, -1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ]),\n",
       " array([0.01831564, 0.04978707, 0.13533528, 0.36787944, 1.        ,\n",
       "        1.        , 1.        , 0.60653066, 0.36787944]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def m(x):\n",
    "    # Implementación de la función m(x)\n",
    "    return np.piecewise(x, [x < 0, (x >= 0)*(x < 1), x >=1], [lambda x: np.exp(2*x), 1, lambda x: np.exp(1-x)])\n",
    "\n",
    "\n",
    "x = np.arange(-2, 2.5, 0.5)\n",
    "#x, np.piecewise(x, [x < 0, x >=1], [lambda x: -x, lambda x: np.exp(1-x)])\n",
    "x, m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
